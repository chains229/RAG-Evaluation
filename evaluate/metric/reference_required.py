# Code hasn't been done yet, thanks for visiting anyway

def ref_required_testcase(question: str, response: str, answer: str):
    """
    Using LLM as a Judge to calculate reference-required metrics.

    Args: question and reference answer from our benchmark, response by LLM generator

    Return: A list of three metrics: Context Relevance, Answer Relevance, Answer Faithfulness
            Each metric contains the score and reason assigned by LLM.

    """
    


    return [
    ]

